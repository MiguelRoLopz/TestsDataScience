{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de clasificación\n",
    "\n",
    "En esta segunda parte del Test 1 de clasificación, nos centraremos en elegir los modelos que se adapten mejor al tipo de datos que hemos preparado en el primer script EDA, analizar sus resultados y justificar la elección en función de métricas clave de rendimiento.\n",
    "\n",
    "Para obtener unos resultados óptimos en este problema de clasificación sin incurrir en tiempos de procesamiento desmedidos, probaremos a implementar los siguientes modelos:\n",
    "\n",
    "· Regresión logística: Intentaremos obtener una referencia inicial de accuracy, precision, ROC-AUC y recall. Es un modelo rápido de entrenar y sencillo de interpretar, por lo que nos dará una idea inicial del comportamiento de los datos.\n",
    "\n",
    "· Ramdom Forest: Entrenaremos un conjunto de árboles de decisión con muestras aleatorias del Dataset para intentar obtener una clasificación más profunda de los datos.\n",
    "\n",
    "· K-Nearest Neighbors (KNN): Clasifica en base a los \"vecinos\" más cercanos. Es sencillo y fácil de interpretar, y para un dataset no demasiado extenso como es el caso, no es costoso computacionalmente.\n",
    "\n",
    "· Support Vector Machines (SVM): Busca el hiperplano que mejor separa las clases en un espacio de características. Puede ser una de las mejores opciones para nuestro caso, ya que es muy efectivo en espacios de características con alta dimensionalidad y con clases bien definidas.\n",
    "\n",
    "## Preparación de los datos\n",
    "\n",
    "· One-hot encoding para las variables categóricas\n",
    "\n",
    "· Separación en datos de entrenamiento y test\n",
    "\n",
    "· Estandarización de las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el Dataset limpio\n",
    "df = pd.read_csv('dataset_EDA.csv')\n",
    "\n",
    "# Definimos características de la variable objetivo\n",
    "X = df.drop(['symboling'], axis=1)\n",
    "y = df['symboling']\n",
    "\n",
    "# Definimos las columnas categóricas y numéricas para el preprocesamiento\n",
    "categorical_columns = ['make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', \n",
    "                       'drive-wheels', 'engine-location', 'horsepower_binned', 'price_binned']\n",
    "\n",
    "numeric_columns = ['normalized-losses', 'wheel-base', 'length', 'width', 'height', \n",
    "                   'curb-weight', 'engine-size', 'bore', 'stroke', 'compression-ratio', \n",
    "                   'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'power_to_weight', 'make_price_ratio']\n",
    "\n",
    "# Dividimos el conjunto de datos en entrenamiento (80%) y test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creamos un transformador para aplicar One-hot encoding a las variables categóricas y estandarización a las numéricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el pipeline de preprocesamiento\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Logística:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       1.00      1.00      1.00         1\n",
      "          -1       0.83      1.00      0.91         5\n",
      "           0       0.87      0.72      0.79        18\n",
      "           1       0.56      0.62      0.59         8\n",
      "           2       0.50      0.60      0.55         5\n",
      "           3       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.73        41\n",
      "   macro avg       0.75      0.78      0.76        41\n",
      "weighted avg       0.75      0.73      0.74        41\n",
      "\n",
      "ROC-AUC: 0.9216106422628162\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo de regresión logística\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_logreg = logreg.predict(X_test_preprocessed)\n",
    "\n",
    "# Métricas de evaluación\n",
    "print(\"Regresión Logística:\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, logreg.predict_proba(X_test_preprocessed), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones del modelo de regresión logística\n",
    "\n",
    "La precisión y el recall promedio ponderados están entorno al 75%, lo que implica que el modelo tiene un buen desempeño general en la predicción de las clases correctas. Los valores -2, -1, 0 y 3 de nuestra variable objetivo 'symboling' son los que mejor se comportan frente al clasificador. Sin embargo, las otras dos clases tienen métricas relativamente bajas, lo que nos sugiere una dificultad del modelo para predecir correctamnete las características en esta clase.\n",
    "\n",
    "El modelo tiene una exactitud de 73%, lo cual es razonable, pero sugiere que hay margen de mejora, especialmente en las clases menos pobladas.\n",
    "\n",
    "El ROC-AUC es de 0.92, lo que implica un buen desempeño en la clasificación en términos generales.\n",
    "\n",
    "La regresión logística muestra un buen rendimiento general, con una alta precisión y recall para algunas clases, pero es mejorable en la clasificación de otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       1.00      1.00      1.00         1\n",
      "          -1       0.83      1.00      0.91         5\n",
      "           0       0.93      0.72      0.81        18\n",
      "           1       0.54      0.88      0.67         8\n",
      "           2       1.00      0.40      0.57         5\n",
      "           3       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.78        41\n",
      "   macro avg       0.85      0.83      0.81        41\n",
      "weighted avg       0.84      0.78      0.78        41\n",
      "\n",
      "ROC-AUC: 0.9774502269067487\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf = rf.predict(X_test_preprocessed)\n",
    "\n",
    "# Métricas de evaluación\n",
    "print(\"Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, rf.predict_proba(X_test_preprocessed), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones del modelo Random Forest\n",
    "\n",
    "La precisión promedio ponderada es del 84%, lo que nos indica que el modelo tiene un buen comportamiento general en este caso. La métrica de recall también muestra valores muy altos para la mayoría de valores de la variable objetivo. Para ambas métricas, la clasificación alcanza el 100% de efectividad en la mayoría de las clases.\n",
    "\n",
    "El F1-score ponderado es del 78%, lo que nos indica un equilibrio más que aceptable entre la precisión y el recall. Las clases -2, -1 y 3 nuevamente muestran un rendimiento elevado.\n",
    "\n",
    "El modelo tiene una exactitud general del 78%, mejor que la ofrecida por el modelo anterior.\n",
    "\n",
    "El ROC-AUC es del 0.9774, un resultado sobresaliente que nos indica que el modelo de Random Forest es muy eficaz en la clasificación general, con un rendimiento excelente a la hora de diferenciar entre las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, creamos un preprocesador con el parámetro 'handle_unknown=ignore' para configurar el OneHotEncoder. Esto permite al codificador manejar categorías desconocidas durante la transformación sin generar errores. Además, incluimos un SimpleImputer para asegurar nuevamente que no haya valores nulos en las variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),\n",
    "        ('cat', Pipeline([\n",
    "            # Incluimos SimpleImputer si es necesario\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_columns)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rtx11679\\Documents\\HybridIntelligence\\MRL-TestDataScience-1\\env1\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors (KNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       1.00      1.00      1.00         1\n",
      "          -1       0.60      0.60      0.60         5\n",
      "           0       0.83      0.56      0.67        18\n",
      "           1       0.62      1.00      0.76         8\n",
      "           2       0.29      0.40      0.33         5\n",
      "           3       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.66        41\n",
      "   macro avg       0.72      0.72      0.70        41\n",
      "weighted avg       0.72      0.66      0.66        41\n",
      "\n",
      "ROC-AUC KNN: 0.8767596153465719\n"
     ]
    }
   ],
   "source": [
    "# Creamos el pipeline para KNN\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Definimos una cuadrícula de búsqueda para ajustar el número de vecinos\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11],  # Ajuste del número de vecinos\n",
    "    'classifier__weights': ['uniform', 'distance']  # Probamos con diferentes pesos\n",
    "}\n",
    "\n",
    "# Usamos GridSearchCV para ajustar los hiperparámetros\n",
    "grid_search_knn = GridSearchCV(knn_pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Mejor estimador encontrado\n",
    "best_knn = grid_search_knn.best_estimator_\n",
    "\n",
    "# Predicciones con el mejor KNN\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "\n",
    "# Métricas de evaluación para KNN con el mejor modelo\n",
    "print(\"K-Nearest Neighbors (KNN):\")\n",
    "print(classification_report(y_test, y_pred_knn, zero_division=0))\n",
    "\n",
    "# ROC-AUC para KNN\n",
    "knn_probabilities = best_knn.predict_proba(X_test)\n",
    "print(\"ROC-AUC KNN:\", roc_auc_score(y_test, knn_probabilities, multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones KNN\n",
    "\n",
    "El modelo KNN tiene un rendimiento decente, pero inferior a los dos modelos anteriores. Aunque es capaz de predecir algunas clases con alta precisión, vemos dificultades para manejar otras, como los valores de symboling 0 y 2. Su exactitud general es del 66% y su ROC-AUC del 0.8767, valores aceptables pero que lo colocan en último lugar, por el momento, en terminos de rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine (SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       1.00      1.00      1.00         1\n",
      "          -1       0.62      1.00      0.77         5\n",
      "           0       0.87      0.72      0.79        18\n",
      "           1       0.56      0.62      0.59         8\n",
      "           2       0.50      0.40      0.44         5\n",
      "           3       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.71        41\n",
      "   macro avg       0.72      0.75      0.72        41\n",
      "weighted avg       0.72      0.71      0.71        41\n",
      "\n",
      "ROC-AUC SVM: 0.9309365195234762\n"
     ]
    }
   ],
   "source": [
    "# Creamos el pipeline para SVM\n",
    "svm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(probability=True, kernel='linear'))  # Usamos kernel 'linear' por simplicidad\n",
    "])\n",
    "\n",
    "# Entrenamos el modelo SVM\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones con SVM\n",
    "y_pred_svm = svm_pipeline.predict(X_test)\n",
    "\n",
    "# Métricas de evaluación para SVM\n",
    "print(\"Support Vector Machine (SVM):\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# ROC-AUC para SVM\n",
    "svm_probabilities = svm_pipeline.predict_proba(X_test)\n",
    "print(\"ROC-AUC SVM:\", roc_auc_score(y_test, svm_probabilities, multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones SVM\n",
    "\n",
    "El modelo SVM ofrece un buen rendimiento, con una exactitud del 71% y un ROC-AUC de 0.9334. Aunque no supera los resultados del Random Forest, SVM se posiciona bien en comparación con la regresión logística y el KNN en términos de precisión, recall y ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones finales\n",
    "\n",
    "El modelo RANDOM FOREST es claramente el mejor en nuestro caso de estudio, con una exactitud del 78% y un ROC-AUC casi perfecto de 0.9774. Este modelo es capaz de manejar mejor las diferentes clases, ofreciendo un rendimiento superior en todas las métricas clave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serialización y guardado del modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf, 'random_forest_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
